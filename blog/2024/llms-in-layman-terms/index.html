<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> LLMs in layman's term | Elijah Soba </title> <meta name="author" content="Elijah Soba"> <meta name="description" content="Explaining LLMs with analogies"> <meta name="keywords" content="elijah, elijah soba, esoba, esoba@umich.edu, elijah portfolio, machine learning blog, machine learning, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/dalle_logo1.png?c561aaa2e846c03dcbc2afc5f520dd26"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://esoba.github.io/blog/2024/llms-in-layman-terms/"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js?0afe9f0ae161375728f7bcc5eb5b4ab4"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Elijah</span> Soba </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about me </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">projects </a> </li> <li class="nav-item "> <a class="nav-link" href="/resources/">resources </a> </li> <li class="nav-item "> <a class="nav-link" href="/assets/pdf/Soba_Elijah_Resume.pdf">resume </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fa-solid fa-moon"></i> <i class="fa-solid fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">LLMs in layman's term</h1> <p class="post-meta"> February 26, 2024 </p> <p class="post-tags"> <a href="/blog/2024"> <i class="fa-solid fa-calendar fa-sm"></i> 2024 </a>   ·   <a href="/blog/tag/nlp"> <i class="fa-solid fa-hashtag fa-sm"></i> NLP</a>   <a href="/blog/tag/genai"> <i class="fa-solid fa-hashtag fa-sm"></i> GenAI</a>     ·   <a href="/blog/category/non-technical"> <i class="fa-solid fa-tag fa-sm"></i> non-technical</a>   </p> </header> <article class="post-content"> <div id="markdown-content"> <h2 id="llm-talk-in-the-wild">LLM talk in the wild</h2> <p>The other day, I heard one of my friends (who works in some business capacity) talking about the work his team was supporting. He said something along the lines of:</p> <p>“I’m working with this AI team that has a model thats able to make classifications on text. Its the same type of technology that ChatGPT uses.”</p> <p>This was before I knew he was on the business side of things, so I excitedly asked him “Are you working with transformers?!?” to which he replied “uuhhhhh maybe”.</p> <p>In another interaction, one of my friends asked me about the work I was doing. He is an actuary and I know he understands/loves math so I started divulging into some of the specifics about LLMs and the work I was doing in Generative AI. At some point he interrupted me with two statements:</p> <p>“Doesn’t ChatGPT just look up information on the internet before answering someones question?”</p> <p>“Wait so how does the model use the internet”</p> <p>A final interaction that stuck with me was talking to my friends cousin about a business opportunity in medical AI. He was a genius doctor/business man that wanted to know how he could integrate “AI” into his workflows to make the doctors office more efficient. I was super excited and started brainstorming a whole bunch of Generative AI ideas like QA over medical documents, automatic scribing, etc. I put together a little pitch and at the end he mentioned it wasn’t exactly what he was looking for. He countered with:</p> <p>“Imagine if we took the app for our practice and sent automated messages reminding people to eat right or get more steps in for the day”.</p> <p>As the hype for Generative AI grows (as it should!), terms like ChatGPT, LLMs, AI, Machine Learning, etc. are all getting bundled together to mean the same thing. I think if you are someone who wants to use Generative AI, it is worth it to understand at a high level what LLMs can/cannot do and how they work. This will not only ground expectations for Generative AI applications, but also make it easier to talk to talent who will eventually make those applications.</p> <h2 id="llms-described-for-a-non-technical-audience">LLMs described for a non-technical audience</h2> <p>Imagine you gave a person, let’s call her Gill, a huge encyclopedia and asked her to read it. After reading, you give her a test: a bunch of open ended questions about the content of the book.</p> <p>How well do you think she would perform?</p> <p>Whatever metric you have in your mind, how much better would she do if she could read the encyclopedia multiple times?</p> <p>Assuming she was able to pass the test eventually, what would the performance look like if she was given a similar test but with information not contained in the encyclopedia?</p> <p>If you can understand this mental model, you can understand LLMs! To get to LLMs, do the following:</p> <ul> <li>Replace the person with a statistical model designed to understand the relationship between texts</li> <li>Replace the encyclopedia with the entire internet</li> <li>Replace the test with any user question</li> </ul> <p>Any question you have about LLMs, first ask the question to Gill. For example:</p> <p>(LLM Question) Why do LLMs return non-factual information?</p> <p>LLM Related Answer:</p> <ul> <li>LLMs learn a probability distribution over next possible tokens in a sequence. When you give an LLM an input it will try to complete it by sampling tokens it thinks should come next (according to the distribution it learned). They are auto-regressive, so they use their own outputs to generate more input. LLMs technically don’t memorize information, if it did it would overfit to the exact specific information it was trained on. Because everything is based on probabilities, sampling can cause information to be false. Likewise, because it is autoregressive, one improperly sampled token creates a downstream affect that can lead to a non-factual answer. Just because a LLM may have seen a particular bit of information during training, doesn’t mean the signal was strong enough to influence the learned probability distribution.</li> </ul> <p>(Converted Gill Question) Why did you get that question on the test wrong?</p> <p>Gills Answer:</p> <p>I read about information regarding the question, but I couldnt remember during the test. It was such a small part of the encyclopedia so I couldnt recall the exact details.</p> <p>(LLM Question) Can LLMs do math?</p> <p>Technically, numbers are also encoded as tokens so they can generate output with numbers. Asking something like “What is 2 + 2” could lead to an LLM, by virtue of its training, to output a high probability for the token “4”. In this sense it can do math, but realistically it is just text completion in a math setting. If you start asking more complex questions, performance will drop considerably because LLMs are text reasoning engines not math reasoning engines. To get LLMs to do math, a better way is to ask the LLM what would be needed to solve the problem (like a particular technique) and have it send extracted numbers to a downstream computer program that can accept the inputs. For example if you ask it what is 100 + 300/2, you can have it reason what steps it needs to take and hook it up to a calculator to do the actual computations.</p> <p>(Converted Gill Question) Based on what you read in the math section of the encylopedia, can you solve this math problem for me?</p> <p>I read about how to solve something like this, but I’ve never had to actual do it. I understand what is being asked but I can’t solve it.</p> <p>I could go on, but most of these questions are going to be future blog posts! Next time you have a high level question about LLMs, think of Gill first.</p> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2024/exploring-llm-uncertainty/">Exploring LLM uncertainty</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2024/i-dont-use-sql-but-i-should/">I don't use SQL as much as I should</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2024/a-note-on-imposter-syndrome/">A note on imposter syndrome</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2024/how-do-pre-trained-embeddings-work/">How do pre-trained sentence embeddings work?</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2022/displaying-external-posts-on-your-al-folio-blog/">Displaying External Posts on Your al-folio Blog</a> </li> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2024 Elijah Soba. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Last updated: June 16, 2024. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2930004b8d7fcd0a8e00fdcfc8fc9f24"></script> <script defer src="/assets/js/common.js?da39b660470d1ba6e6b8bf5f37070b6e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>